{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "pd.options.display.max_columns = None \n",
    "pd.options.display.max_rows = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miazh_000\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_accepted = pd.read_csv('accepted_2007_to_2018Q4.csv') \n",
    "df_rejected = pd.read_csv('rejected_2007_to_2018Q4.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_accepted = df_raw_accepted.sample(frac=0.1) \n",
    "# df_rejected = df_raw_accepted.sample(frac=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_accepted = pd.read_csv('sample_accepted.csv') \n",
    "# df_rejected = pd.read_csv('sample_rejected.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27648741, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rejected.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260701, 151)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accepted.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For applications prior to November 5, 2013 the risk score is the borrower's FICO score. \n",
    "For applications after November 5, 2013 the risk score is the borrower's Vantage score.\n",
    "'''\n",
    "\n",
    "def data_process(df_accepted,df_rejected,dummy = False):\n",
    "    \n",
    "    accepted = df_accepted.copy() \n",
    "    rejected = df_rejected.copy() \n",
    "    \n",
    "    # Processing accepted data \n",
    "    accepted = accepted[['loan_amnt', 'purpose', 'dti',\n",
    "#        'zip_code', \n",
    "       'addr_state', 'emp_length', 'issue_d',\n",
    "       'loan_status', 'last_fico_range_high','last_fico_range_low']]\n",
    "    \n",
    "    accepted['issue_d'] = pd.to_datetime(accepted['issue_d'])\n",
    "    accepted['app_year'] = accepted['issue_d'].dt.year \n",
    "    accepted['app_month'] = accepted['issue_d'].dt.month \n",
    "\n",
    "    accepted['risk_score'] = (accepted['last_fico_range_high'] + accepted['last_fico_range_low'])/2 \n",
    "    accepted = accepted.drop(columns = ['issue_d','last_fico_range_high','last_fico_range_low']) \n",
    "\n",
    "#     if reverse = False:\n",
    "#         accepted = accepted.replace({'loan_status' : { 'Charged Off' : 'rejected', 'Late (16-30 days)' : 'rejected', \n",
    "#                                        'Late (31-120 days)' : 'rejected',\n",
    "#                                        'Does not meet the credit policy. Status:Charged Off' : 'rejected',\n",
    "#                                        'Fully Paid' : 'accepted', 'Current' : 'accepted',\n",
    "#                                        'In Grace Period' : 'accepted',\n",
    "#                                        'Does not meet the credit policy. Status:Fully Paid' : 'accepted'}})\n",
    "\n",
    "    accepted['loan_status'] =1\n",
    "            \n",
    "    \n",
    "    # Processing rejected data \n",
    "    rejected = rejected[['Amount Requested', 'Application Date', 'Loan Title',\n",
    "#        'zip_code', \n",
    "       'Risk_Score', 'Debt-To-Income Ratio', 'Zip Code',\n",
    "       'State','Employment Length']]\n",
    "    \n",
    "    rejected = rejected.rename(columns={\"Amount Requested\": \"loan_amnt\", \"Application Date\": \"app_date\", \"Loan Title\": \"purpose\",\n",
    "                             \"Risk_Score\": \"risk_score\", \"Debt-To-Income Ratio\": \"dti\", \"Zip Code\": \"zip_code\",\n",
    "                             \"State\": \"addr_state\", \"Employment Length\": \"emp_length\"})\n",
    "    rejected['loan_status'] = 0\n",
    "    \n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*consolidation.*$)', 'debt_consolidation') \n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*loan.*$)', 'debt_consolidation') \n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*debt.*$)', 'debt_consolidation')\n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*card.*$)', 'credit_card')\n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*credit.*$)', 'credit_card')\n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*house.*$)', 'house') \n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*business.*$)', 'small_business')\n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*car.*$)', 'car')\n",
    "    rejected['purpose'] = rejected['purpose'].str.replace(r'(^.*education.*$)', 'education')\n",
    "    \n",
    "    \n",
    "    rejected['purpose'] = np.where(rejected['purpose'].isin(['house', 'credit_card', 'major_purchase', 'debt_consolidation',\n",
    "       'other', 'moving', 'small_business', 'home_improvement',\n",
    "       'vacation', 'medical', 'renewable_energy', 'car', 'wedding']), rejected['purpose'], 'other')\n",
    "\n",
    "    rejected['app_date'] = pd.to_datetime(rejected['app_date'])\n",
    "    rejected['app_year'] = rejected['app_date'].dt.year\n",
    "    rejected['app_month'] = rejected['app_date'].dt.month\n",
    "\n",
    "    rejected = rejected.drop(columns = 'app_date')\n",
    "    rejected = rejected.drop(columns = 'zip_code')\n",
    "    \n",
    "    rejected['dti'] = rejected['dti'].str.replace('%','')\n",
    "    \n",
    "    # Merge accepted and rejected data for later process\n",
    "    df_processed = pd.concat([accepted, rejected], sort=True)\n",
    "    \n",
    "\n",
    "    # Convert categorical to numerical-- 10 means more than 10 years \n",
    "    df_processed['emp_length'] = df_processed['emp_length'].str.extract('(\\d+)')\n",
    "\n",
    "\n",
    "    # Missing Values: risk_score, emp_length, dti\n",
    "    df_processed['emp_length'] = df_processed['emp_length'].fillna(0)\n",
    "    df_processed['emp_length'] = df_processed['emp_length'].astype(int)\n",
    "    df_processed['risk_score'] = df_processed['risk_score'].fillna(0)\n",
    "    df_processed['dti'] = df_processed['dti'].fillna(0)\n",
    "    df_processed['dti'] = df_processed['dti'].astype(float)\n",
    "    df_processed = df_processed.dropna()\n",
    "    \n",
    "    \n",
    "    df_undummpy = df_processed.copy()\n",
    "    df_processed = pd.get_dummies(df_processed)\n",
    "    \n",
    "    if dummy == False:\n",
    "        return df_processed\n",
    "\n",
    "    if dummy == True:\n",
    "        return df_undummpy\n",
    "    \n",
    "df_processed = data_process(df_accepted,df_rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_processed.groupby(['app_year', 'loan_status']).size().reset_index(name='counts')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted['issue_d'] = pd.to_datetime(df_accepted['issue_d'])\n",
    "df_accepted['app_year'] = df_accepted['issue_d'].dt.year\n",
    "df_accepted.groupby(['app_year']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted.groupby(['app_year']).agg({'funded_amnt': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted['emp_length'] = df_accepted['emp_length'].str.extract('(\\d+)')\n",
    "\n",
    "# Missing Values: risk_score, emp_length, dti\n",
    "df_accepted['emp_length'] = df_accepted['emp_length'].fillna(0)\n",
    "df_accepted['emp_length'] = df_accepted['emp_length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted.groupby(['app_year']).agg({'emp_length': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted['risk_score'] = (df_accepted['last_fico_range_high'] + df_accepted['last_fico_range_low'])/2\n",
    "df_accepted['risk_score'] = df_accepted['risk_score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted.groupby(['app_year']).agg({'risk_score': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accepted[df_accepted.loan_status == 'Charged Off'].groupby(['app_year']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rejected['app_date'] = pd.to_datetime(df_rejected['Application Date'])\n",
    "df_rejected['app_year'] = df_rejected['app_date'].dt.year\n",
    "df_rejected.groupby(['app_year']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.groupby(['loan_status']).agg({'loan_amnt': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rejected.groupby(['Loan Title']).size().reset_index(name='counts').sort_values(by='counts',ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_nostatus = df_processed.drop(['loan_status'], axis = 1)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "df_processed_nostatus = scaler.fit_transform(df_processed_nostatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(df_processed_nostatus)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 10), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, init='k-means++', max_iter=300, n_init=10)\n",
    "kmeans = kmeans.fit(df_processed_nostatus)\n",
    "labels = kmeans.predict(df_processed_nostatus)\n",
    "C = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed ['label'] = labels.tolist()\n",
    "df_processed.groupby(['label','loan_status']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements = np.unique(labels)\n",
    "unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in unique_elements:\n",
    "    print('label: ', x)\n",
    "    print(df_processed[df_processed['label']==x].sample(10))\n",
    "    print('-----------------------------------------------')\n",
    "    print(df_processed[df_processed['label']==x].describe())\n",
    "    print('-----------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
